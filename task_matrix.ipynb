{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc194db-8b90-4cc6-a5ab-b12f98501384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'TaskMatrix'...\n",
      "remote: Enumerating objects: 577, done.\u001b[K\n",
      "remote: Counting objects: 100% (577/577), done.\u001b[K\n",
      "remote: Compressing objects: 100% (354/354), done.\u001b[K\n",
      "remote: Total 577 (delta 219), reused 527 (delta 204), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (577/577), 40.24 MiB | 13.99 MiB/s, done.\n",
      "Resolving deltas: 100% (219/219), done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!git clone https://github.com/microsoft/TaskMatrix.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9986bdc-64bf-468e-8072-89139e553b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to directory\n",
    "\n",
    "!cd TaskMatrix && pip install -r requirements.txt && pip install  git+https://github.com/IDEA-Research/GroundingDINO.git && pip install  git+https://github.com/facebookresearch/segment-anything.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a416bfb-0ee9-4d4b-8bde-1375e686df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1786f31-0256-4d56-b706-792175a3c8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
      "  warnings.warn(\n",
      "Initializing VisualChatGPT, load_dict={'ImageCaptioning': 'cuda:0', 'VisualQuestionAnswering': 'cuda:0'}\n",
      "Initializing ImageCaptioning to cuda:0\n",
      "Initializing VisualQuestionAnswering to cuda:0\n",
      "All the Available Functions: {'ImageCaptioning': <__main__.ImageCaptioning object at 0x7f3ab8704550>, 'VisualQuestionAnswering': <__main__.VisualQuestionAnswering object at 0x7f3ab8704520>}\n",
      "visual_chatgpt.py:1569: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  txt = gr.Textbox(show_label=False, placeholder=\"Enter text and press enter, or upload an image\").style(\n",
      "Running on local URL:  http://0.0.0.0:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: Get Photo Description\n",
      "Action Input: image/chinese_indian.png\u001b[0mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/gradio/routes.py\", line 442, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/gradio/blocks.py\", line 1392, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/gradio/blocks.py\", line 1097, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/gradio/utils.py\", line 703, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"visual_chatgpt.py\", line 1520, in run_text\n",
      "    res = self.agent({\"input\": text.strip()})\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/langchain/chains/base.py\", line 168, in __call__\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/langchain/chains/base.py\", line 165, in __call__\n",
      "    outputs = self._call(inputs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/langchain/agents/agent.py\", line 503, in _call\n",
      "    next_step_output = self._take_next_step(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/langchain/agents/agent.py\", line 420, in _take_next_step\n",
      "    observation = tool.run(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/langchain/tools/base.py\", line 71, in run\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/langchain/tools/base.py\", line 68, in run\n",
      "    observation = self._run(tool_input)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/langchain/agents/tools.py\", line 17, in _run\n",
      "    return self.func(tool_input)\n",
      "  File \"visual_chatgpt.py\", line 314, in inference\n",
      "    inputs = self.processor(Image.open(image_path), return_tensors=\"pt\").to(self.device, self.torch_dtype)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 3236, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'image/chinese_indian.png'\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Action: Get Photo Description\n",
      "Action Input: image/elon_musk.png\u001b[0mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/gradio/routes.py\", line 442, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/gradio/blocks.py\", line 1392, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/gradio/blocks.py\", line 1097, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/gradio/utils.py\", line 703, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"visual_chatgpt.py\", line 1520, in run_text\n",
      "    res = self.agent({\"input\": text.strip()})\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/langchain/chains/base.py\", line 168, in __call__\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/langchain/chains/base.py\", line 165, in __call__\n",
      "    outputs = self._call(inputs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/langchain/agents/agent.py\", line 503, in _call\n",
      "    next_step_output = self._take_next_step(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/langchain/agents/agent.py\", line 420, in _take_next_step\n",
      "    observation = tool.run(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/langchain/tools/base.py\", line 71, in run\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/langchain/tools/base.py\", line 68, in run\n",
      "    observation = self._run(tool_input)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/langchain/agents/tools.py\", line 17, in _run\n",
      "    return self.func(tool_input)\n",
      "  File \"visual_chatgpt.py\", line 314, in inference\n",
      "    inputs = self.processor(Image.open(image_path), return_tensors=\"pt\").to(self.device, self.torch_dtype)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 3236, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'image/elon_musk.png'\n",
      "======>Auto Resize Image...\n",
      "Resize image form 1008x740 to 512x384\n",
      "\n",
      "Processed ImageCaptioning, Input Image: image/5dfd5f0f.png, Output Text: a bar chart showing the number of items in each of the items\n",
      "\n",
      "Processed run_image, Input image: image/5dfd5f0f.png\n",
      "Current state: [('![](file=image/5dfd5f0f.png)*image/5dfd5f0f.png*', 'Received.  ')]\n",
      "Current Memory: \n",
      "Human: provide a figure named image/5dfd5f0f.png. The description is: a bar chart showing the number of items in each of the items. This information helps you to understand this image, but you should use tools to finish following tasks, rather than directly imagine from my description. If you understand, say \"Received\". \n",
      "AI: Received.  \n",
      "history_memory:\n",
      "Human: provide a figure named image/5dfd5f0f.png. The description is: a bar chart showing the number of items in each of the items. This information helps you to understand this image, but you should use tools to finish following tasks, rather than directly imagine from my description. If you understand, say \"Received\". \n",
      "AI: Received.  , n_tokens: 53\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYes\n",
      "Action: Answer Question About The Image\n",
      "Action Input: image/5dfd5f0f.png, what is in this image?\u001b[0m\n",
      "Processed VisualQuestionAnswering, Input Image: image/5dfd5f0f.png, Input Question:  what is in this image?, Output Answer: barcode\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mbarcode\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAI: The image you provided is a bar chart showing the number of items in each of the items.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Processed run_text, Input text:  image/5dfd5f0f.png  whats in the image?\n",
      "Current state: [('![](file=image/5dfd5f0f.png)*image/5dfd5f0f.png*', 'Received.  '), (' image/5dfd5f0f.png  whats in the image?', 'The image you provided is a bar chart showing the number of items in each of the items.')]\n",
      "Current Memory: \n",
      "Human: provide a figure named image/5dfd5f0f.png. The description is: a bar chart showing the number of items in each of the items. This information helps you to understand this image, but you should use tools to finish following tasks, rather than directly imagine from my description. If you understand, say \"Received\". \n",
      "AI: Received.  \n",
      "Human: image/5dfd5f0f.png  whats in the image?\n",
      "AI: The image you provided is a bar chart showing the number of items in each of the items.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!cd TaskMatrix && python visual_chatgpt.py --load \"ImageCaptioning_cuda:0,VisualQuestionAnswering_cuda:0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f65b4-bc88-4edc-a2c8-db2cb863f789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017106e8-5406-4bfd-b255-a528dbf88d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1d79d7-9fde-4721-8fb7-c26103d64e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e0cfc8-8d73-42fa-ae7f-3ec1a518df8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c31ab54-aa65-46f6-b7ab-132aad0f10ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15696d68-7d5e-4135-93be-51e53f163430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f76ba18-f6a9-4f80-b408-c8823d978d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f1009-6052-4ae9-b5f7-6b8b0c6c74ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34da08b-be70-4142-ab4a-2af2d783caf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac60832-cf5e-4a2f-971e-0eaf93b54ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a62117-8ca6-4b4b-ad8f-0f64e83746d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f95e990-4448-44c3-af77-de8433b35151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a75619-7f15-4049-b13b-681b4cdd3ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f32b0d1-aca9-4255-91cd-311f02e25de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33327203-dcc4-41b4-8e06-e8ae93dc6527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9351ebf7-c5d7-4b43-b246-0b621d0ce3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

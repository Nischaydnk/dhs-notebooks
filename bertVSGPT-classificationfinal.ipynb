{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "310f80ce-1d3f-411c-a556-79897e8d37e7",
   "metadata": {},
   "source": [
    "# GPT vs BERT Fine-Tune for downstream NLP tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b6167b-a68a-48e3-8e1a-cecaa3d7dd10",
   "metadata": {},
   "source": [
    "### In this notebook, we will:\n",
    "\n",
    "    - Finetune Transformer based models for summarisation task\n",
    "    - Prompt Engineer GPT models\n",
    "    - Live results comparision\n",
    "    - Performance evaluation w/ different metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bed0aa-711c-4be2-87a5-5a8a2b43c552",
   "metadata": {},
   "source": [
    "##### We will be using a labeled dataset for summarisation. The dataset is preprocessed and splitted into training, validation, and test dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1cfc78-86c3-40a0-8322-f9377c44b30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install accelerate evaluate openai scikit-learn langchain datasets transformers -qq\n",
    "!pip install --upgrade langchain -qq \n",
    "!pip install --upgrade python-dotenv -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "796a4834-ff21-42e4-8f50-e887c12eb1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import openai\n",
    "import os\n",
    "import IPython\n",
    "from langchain.llms import OpenAI\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9182ced9-8feb-4a6b-93a9-35996f6d1dfa",
   "metadata": {},
   "source": [
    "### Enter OpenAI Key \n",
    "\n",
    "##### https://platform.openai.com/account/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616f13f9-9612-4a42-9957-844c9f2094cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key  = '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' # this key must be changed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "627c5d6f-caa0-49d4-939e-a82adfb25f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af46575e4e1846bf98eebdfd93835706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817f9f758a924b3d98a87e9e660a2c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.50M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9828020be07a417f9a3f0e67b0e29653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536be2aafe6642b199ac7bc7c68e0fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"NischayDnk/bertvsllm_demodatav2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dff6f9b3-889d-4b7f-bbe7-197efcff7656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['textID', 'text', 'selected_text', 'sentiment'],\n",
       "        num_rows: 27481\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7d03a1a-86c3-4d8e-be34-27c5b1ac110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d773a03-bb3d-4269-bfc1-e93743175743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text   \n",
       "0  cb774db0d1                I`d have responded, if I were going  \\\n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "751781a1-5154-406f-8517-119dc924313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_test_df = train_test_split(df, train_size=0.8, random_state=42, stratify=df['sentiment'])\n",
    "\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.5, random_state=42, stratify=val_test_df['sentiment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aad7166c-89e6-4612-a443-ee3468993cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8cd1550-f5be-48d1-973f-b211953f4b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "neutral     8894\n",
      "positive    6865\n",
      "negative    6225\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.sentiment.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5714185-8f4a-47b5-a168-9e9971ce80a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f360622a-56c7-4178-90ae-3660d75ae8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "id2label = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "label2id = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "\n",
    "train_df['label'] = train_df['sentiment'].map(label2id)\n",
    "val_df['label'] = val_df['sentiment'].map(label2id)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=3, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de49ec1c-bb3e-404f-ada6-b8b26047253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4e57279-3670-4624-a646-721ae489d7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df[['text','label']].tail(3000), split='train')\n",
    "valid_dataset = Dataset.from_pandas(val_df[['text','label']].head(500), split='valid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c31a15f2-192e-4ea0-a464-6170d53fa874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3dd8760afa4a668a293c06a6f8d064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1b1834c93446d9ae05764c91a785d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dynamic_padding = True\n",
    "\n",
    "def tokenize_func(examples):\n",
    "\treturn tokenizer(examples[\"text\"], padding=True)  \n",
    "\n",
    "encoded_dataset_train = train_dataset.map(tokenize_func, batched=True)\n",
    "encoded_dataset_valid = valid_dataset.map(tokenize_func, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ecfbc44-554e-47ed-983f-b222b4f207ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"exp1_bert\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset_train,\n",
    "    eval_dataset=encoded_dataset_valid,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b913d58e-eccd-4542-8e51-6c76505d6d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnischay\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nischay/av_llmworld/wandb/run-20230804_065520-gqd31be7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nischay/huggingface/runs/gqd31be7' target=\"_blank\">toasty-pine-14</a></strong> to <a href='https://wandb.ai/nischay/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nischay/huggingface' target=\"_blank\">https://wandb.ai/nischay/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nischay/huggingface/runs/gqd31be7' target=\"_blank\">https://wandb.ai/nischay/huggingface/runs/gqd31be7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [189/189 00:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.578704</td>\n",
       "      <td>0.768000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.540561</td>\n",
       "      <td>0.768000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.531405</td>\n",
       "      <td>0.774000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=189, training_loss=0.6066558676421958, metrics={'train_runtime': 24.3118, 'train_samples_per_second': 370.191, 'train_steps_per_second': 7.774, 'total_flos': 256142701980000.0, 'train_loss': 0.6066558676421958, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "688f136e-4ec0-4683-8d6c-39e204b0d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "858293cb-98dd-4356-ac2c-ea6c62b3acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = 'exp1_bert/checkpoint-564/'\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2886d8d4-5dc3-4520-bb40-95e1c28bc47a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "436f8808-cf35-46d8-835c-b2099e888373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 16s, sys: 351 ms, total: 13min 16s\n",
      "Wall time: 24.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_texts = test_df['text'].tolist()\n",
    "test_labels = test_df['sentiment'].tolist()\n",
    "\n",
    "# Tokenize the test data and convert it to DataLoader\n",
    "inputs = tokenizer(test_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "test_dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'])\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "# Make predictions on the test data using the trained model\n",
    "bert_model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids, attention_mask = batch\n",
    "        logits = bert_model(input_ids, attention_mask=attention_mask)[0]\n",
    "        batch_predictions = torch.argmax(logits, dim=1).tolist()\n",
    "        predictions.extend(batch_predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "683c21c6-7e88-4072-917d-f7a38f8f3fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  rain\n",
      "Actual Label: neutral\n",
      "Model Prediction: neutral\n",
      "\n",
      "Text:  umm well i only go to house clubs and i never go to north beach so.no idea, sorry  been out 1x there 2 a now defunctlesi club\n",
      "Actual Label: negative\n",
      "Model Prediction: neutral\n",
      "\n",
      "Text: getting ready to head out to Camp Allen.  Unless somethings changed, that means no phone service for about 24 hours.\n",
      "Actual Label: neutral\n",
      "Model Prediction: neutral\n",
      "\n",
      "Text: Twitter won`t let me update online. My update box won`t work.\n",
      "Actual Label: negative\n",
      "Model Prediction: negative\n",
      "\n",
      "Text:  is over\n",
      "Actual Label: neutral\n",
      "Model Prediction: neutral\n",
      "\n",
      "Text: _Photography Good Morning! Hope you have a great day!!\n",
      "Actual Label: positive\n",
      "Model Prediction: positive\n",
      "\n",
      "Text: started her new job today! aaand so stoked for may long..  and billy is awesome.\n",
      "Actual Label: positive\n",
      "Model Prediction: positive\n",
      "\n",
      "Text:  I forgot about it and I already ate lunch  so I guess I`m not going.\n",
      "Actual Label: neutral\n",
      "Model Prediction: negative\n",
      "\n",
      "Text: _0407 all over the place it was  boo, dual voice challenge was too challenging\n",
      "Actual Label: neutral\n",
      "Model Prediction: negative\n",
      "\n",
      "Text:  does it work on the iPhone as my MacBook is flat\n",
      "Actual Label: neutral\n",
      "Model Prediction: neutral\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to display the fancy output\n",
    "output_df = pd.DataFrame({'Text': test_texts, 'Actual Label': test_labels, 'Model Prediction': predictions})\n",
    "output_df['Model Prediction'] = output_df['Model Prediction'].map(id2label)\n",
    "\n",
    "def format_output(row):\n",
    "    return f\"Text: {row['Text']}\\nActual Label: {row['Actual Label']}\\nModel Prediction: {row['Model Prediction']}\\n\"\n",
    "\n",
    "formatted_output = output_df.head(10).apply(format_output, axis=1).tolist()\n",
    "print(\"\\n\".join(formatted_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b6b0ac-5e55-4d89-81d4-b9f26ba49f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e86580ab-a03c-4eca-ba24-1760e0bb8114",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f20c28f3-c6e6-40c8-9192-317a858d6b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = output_df[:120]\n",
    "output_df['gpt_pred'] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "afeb63c4-4f12-405e-bd69-45d0e81924ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Actual Label</th>\n",
       "      <th>Model Prediction</th>\n",
       "      <th>gpt_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rain</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>umm well i only go to house clubs and i never...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Actual Label   \n",
       "0                                               rain      neutral  \\\n",
       "1   umm well i only go to house clubs and i never...     negative   \n",
       "\n",
       "  Model Prediction gpt_pred  \n",
       "0          neutral           \n",
       "1          neutral           "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0a66a7c0-7d1d-4330-95f3-dc1f23ab2e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6031cc97-c772-4417-b340-e9ffc02be1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import ast\n",
    "\n",
    "def get_sentiments(texts):\n",
    "    prompts = \"\".join([f\"\"\"\n",
    "    ---- {text}.\n",
    "    ----\n",
    "    \"\"\" for text in texts])\n",
    "    prompts += '''\\nGiven a list of texts above. \\nEach text is seperated by ---- . Return me a python list in the same order as the text, with each value in the\n",
    "    list representing the sentiment of the sentence. \n",
    "    The sentiment of the sentence can be one of the following 3 values:\n",
    "\n",
    "    1. negative:\n",
    "    2. neutral\n",
    "    3. positive\n",
    "\n",
    "    All the sentences are twitter tweets, and you are the best ML sentiment classification model.\n",
    "\n",
    "    You must just return a python list and nothing else.\n",
    "    '''\n",
    "\n",
    "    return prompts\n",
    "    \n",
    "    # prompts += 'you have these options to predict sentiment / toxicity'\n",
    "    # prompts += 'negative'\n",
    "    # prompts += 'neutral'\n",
    "    # prompts += 'positive'\n",
    "\n",
    "    # prompts += 'what abbreviation corresponds to the right sentiment?'\n",
    "    # prompts += 'Generate reponse in example format: negative ---- neutral --- negative ---- positive ....'\n",
    "    # prompts += 'Please keep the number of responses generated exact same as prompt texts.'\n",
    "    \n",
    "\n",
    "\n",
    "# prompts = get_sentiments(output_df.Text[start:end].values[:10])\n",
    "# responses = get_completion(prompts)\n",
    "#     responses = responses.split('-----')#[:-1] \n",
    "\n",
    "\n",
    "#     print(prompts,'prompt')\n",
    "#     # print('\\n')\n",
    "#     # print('\\n')\n",
    "#     print(responses,'responses')\n",
    "    \n",
    "#     sentiments = []\n",
    "#     for response in responses:\n",
    "#         if 'negative' in response:\n",
    "#             sentiments.append('negative')\n",
    "#         elif 'neutral' in response:\n",
    "#             sentiments.append('neutral')\n",
    "#         elif 'positive' in response:\n",
    "#             sentiments.append('positive')\n",
    "#         else:\n",
    "#             sentiments.append('neutral') # in case the response does not match any known sentiments\n",
    "#     return sentiments\n",
    "\n",
    "start = 0\n",
    "step=20\n",
    "end = start + step # process 10 rows at once\n",
    "\n",
    "while start < len(output_df):\n",
    "    print(start, end)\n",
    "    selected_rows = output_df.Text[start:end-1].values\n",
    "    prompts = get_sentiments(selected_rows)\n",
    "    responses = get_completion(prompts)\n",
    "    responses = ast.literal_eval(responses)\n",
    "    output_df.loc[start:end-1, 'gpt_pred'] = responses\n",
    "    start = end\n",
    "    end = min(end + step, len(output_df)) \n",
    "    time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "265fd1aa-7f8f-4c52-ac98-f67253f215ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 20\n",
      "20 40\n",
      "40 60\n",
      "60 80\n",
      "80 100\n"
     ]
    }
   ],
   "source": [
    "def format_output(row):\n",
    "    return f\"Text: {row['Text']}\\nActual Label: {row['Actual Label']}\\nModel Prediction: {row['Model Prediction']}\\nGPT Prediction: {row['gpt_pred']}\\n\"\n",
    "\n",
    "formatted_output = output_df.head(10).apply(format_output, axis=1).tolist()\n",
    "print(\"\\n\".join(formatted_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "960cd807-840c-4e72-8d26-d6099421754b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      neutral\n",
       "1      neutral\n",
       "2      neutral\n",
       "3      neutral\n",
       "4      neutral\n",
       "        ...   \n",
       "95     neutral\n",
       "96    positive\n",
       "97     neutral\n",
       "98    negative\n",
       "99    negative\n",
       "Name: gpt_pred, Length: 100, dtype: object"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df['gpt_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5ef561c8-a33a-4475-8acc-6caff1be9709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6cd2c254-6ba0-44d1-81ec-b773f737ef04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpt_pred\n",
       "neutral     0.42\n",
       "positive    0.29\n",
       "negative    0.29\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df['gpt_pred'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81200844-b682-4d6e-9f12-dd88d909b8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "668f124e-988c-4738-81de-65146f3c24b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT Accuracy: 0.58\n",
      "Bert Accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gpt_predictions = output_df['gpt_pred'].tolist()\n",
    "bert_predictions = output_df['Model Prediction'].tolist()\n",
    "\n",
    "gpt_accuracy = accuracy_score(output_df['Actual Label'].tolist(), gpt_predictions)\n",
    "bert_accuracy = accuracy_score(output_df['Actual Label'].tolist(), bert_predictions)\n",
    "\n",
    "print(f\"GPT Accuracy: {gpt_accuracy}\")\n",
    "print(f\"Bert Accuracy: {bert_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c97ae-c191-418e-9b22-ebe42b3185be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18822234-e5b4-4264-885f-351acfbb7045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72a2c98-0648-4873-99a5-14e956390dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c3761-1cbe-4b1d-ac34-b0227133ec18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c978ef34-01bb-4038-aae6-9498f1f61dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442c0ce3-bf43-4960-b3c7-d510f36bb2cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540f9227-300c-4d1b-9b30-e7b07e5923dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e770cc-e900-4f47-9a79-eb2eb162618e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205a3c5a-2832-4241-af4a-90a51e2027ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230a3aa3-e836-41a1-bb29-ea603ba31f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe66256-ee9d-49ca-a231-247ad95d7605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae36d5f-75a2-48e7-ade6-2a3d7fbb2048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e2dbdf-6a04-4b29-8d8c-735507b5ca32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
